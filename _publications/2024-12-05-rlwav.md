---
title: "Reinforcement Learning from Wild Animal Videos"
collection: publications
category: conferences
permalink: /publication/2024-12-05-rlwav
excerpt: 'We present RLWAV, a method to teach legged robots locomotion skills by learning from thousands of wild animal videos. Using a video classifier and reinforcement learning, our approach enables a robot to acquire diverse behaviors like walking and jumping in simulation and transfers these skills directly to a real quadruped, despite the domain and embodiment gap.'
date: 2024-12-05'
venue: 'arxiv'
projectpage: 'https://elliotchanesane31.github.io/RLWAV/'
paperurl: 'https://arxiv.org/abs/2412.04273'
citation: 'Elliot Chane-Sane, Constant Roux, Olivier Stasse, Nicolas Mansard. Reinforcement Learning from Wild Animal Videos.'
---
# Abstract
We propose to learn legged robot locomotion skills by watching thousands of wild animal videos from the internet, such as those featured in nature documentaries. Indeed, such videos offer a rich and diverse collection of plausible motion examples, which could inform how robots should move. To achieve this, we introduce Reinforcement Learning from Wild Animal Videos (RLWAV), a method to ground these motions into physical robots. We first train a video classifier on a large-scale animal video dataset to recognize actions from RGB clips of animals in their natural habitats. We then train a multi-skill policy to control a robot in a physics simulator, using the classification score of a third-person camera capturing videos of the robot's movements as a reward for reinforcement learning. Finally, we directly transfer the learned policy to a real quadruped Solo. Remarkably, despite the extreme gap in both domain and embodiment between animals in the wild and robots, our approach enables the policy to learn diverse skills such as walking, jumping, and keeping still, without relying on reference trajectories nor skill-specific rewards. 
